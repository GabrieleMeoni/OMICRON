{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 97 118\n",
      "..\\data\\Cloud\\img_msec_1608603767961_2_half_1.png\n"
     ]
    }
   ],
   "source": [
    "# Get all data paths\n",
    "import os\n",
    "paths = {0: [], 1: [], 2: []}\n",
    "folder_names = [\"Cloud\", \"Edge\", \"Good\"]\n",
    "for i, folder_name in enumerate(folder_names):\n",
    "    folder_path = os.path.join(\"..\\data\", folder_name)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        paths[i].append(os.path.join(folder_path, file_name))\n",
    "print(f\"Cloud: {len(paths[0])}, Edge: {len(paths[1])}, Good: {len(paths[2])}\")\n",
    "print(f\"Example path: {paths[0][0]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.preprocess import PrePostProcessor, ResizeAlgorithm, ColorFormat\n",
    "from openvino.runtime import Core, Layout, Type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# (.xml and .bin files) or (.onnx file)\n",
    "model_path = 'models/model_mobilenet_v2.onnx'\n",
    "device_name = 'MYRIAD'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OpenVINO Runtime Core\n"
     ]
    }
   ],
   "source": [
    "# Initialize openvino runtime core\n",
    "print('Creating OpenVINO Runtime Core')\n",
    "core = Core()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the model: model_mobilenet_v2.onnx\n"
     ]
    }
   ],
   "source": [
    "# Read ONNX model\n",
    "print(f'Reading the model: {model_path}')\n",
    "model = core.read_model(model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images\n",
      "Putting images into numpy array\n"
     ]
    }
   ],
   "source": [
    "# Read input image\n",
    "image_paths = paths[0] + paths[1] + paths[2]\n",
    "images = []\n",
    "print(\"Reading images, this may take a while\")\n",
    "for path in image_paths:\n",
    "    image = cv2.imread(path)\n",
    "    # make grayscale\n",
    "    image = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)\n",
    "    # Not all images are the same size, force resize so model can handle it\n",
    "    if image.shape == (1942, 1024, 3):\n",
    "        images.append(image)\n",
    "    else:\n",
    "        images.append(cv2.resize(image, (1024, 1942)))\n",
    "print(\"Putting images into numpy array\")\n",
    "complete_tensor = np.array(images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 1\n",
    "example_input = complete_tensor[:batch_size]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Preprocess input image\n",
    "ppp = PrePostProcessor(model)\n",
    "\n",
    "_, h, w, _ = example_input.shape\n",
    "\n",
    "# 1) Set input tensor information:\n",
    "# - input() provides information about a single model input\n",
    "# - reuse shape from already available `example_input`\n",
    "# - layout of data is 'NHWC'\n",
    "# - cv2 reads image as BGR and uses uint8 as dtype\n",
    "ppp.input().tensor() \\\n",
    "    .set_shape(example_input.shape) \\\n",
    "    .set_element_type(Type.u8) \\\n",
    "    .set_color_format(ColorFormat.BGR) \\\n",
    "    .set_layout(Layout('NHWC'))  # noqa: ECE001, N400\n",
    "\n",
    "# These were the mean and standard deviation used to train the model\n",
    "dataset_mean = [0.2391, 0.4028, 0.4096]\n",
    "dataset_std = [0.2312, 0.3223, 0.3203]\n",
    "# 2) Adding explicit preprocessing steps:\n",
    "# - apply linear resize from tensor spatial dims to model spatial dims\n",
    "# - convert element type from uint8 to float32\n",
    "# - convert color format from BGR to RGB\n",
    "# - scale values from [0, 255] to [0, 1]\n",
    "# - subtract mean values\n",
    "# - scale values by standard deviation\n",
    "ppp.input().preprocess()\\\n",
    "    .resize(ResizeAlgorithm.RESIZE_LINEAR)\\\n",
    "    .convert_element_type(Type.f32)\\\n",
    "    .convert_color(ColorFormat.RGB)\\\n",
    "    .scale(255)\\\n",
    "    .mean(dataset_mean)\\\n",
    "    .scale(dataset_std)\n",
    "\n",
    "# These are the steps that were used to train the model:\n",
    "# transform = transforms.Compose([v2.ToImage(),\n",
    "#                                 v2.Resize((int(256), int(256))),\n",
    "#                                 v2.RandomHorizontalFlip(p=0.5),\n",
    "#                                 v2.RandomVerticalFlip(p=0.5),\n",
    "#                                 v2.ToDtype(torch.float32, scale=True),\n",
    "#                                 v2.Grayscale(num_output_channels=3),\n",
    "#                                 v2.Normalize(dataset_mean,dataset_std)\n",
    "#                                 ])\n",
    "\n",
    "# 3) Here we suppose model has 'NCHW' layout for input\n",
    "ppp.input().model().set_layout(Layout('NCHW'))\n",
    "\n",
    "# 4) Set output tensor information:\n",
    "# - precision of tensor is supposed to be 'f32'\n",
    "ppp.output().tensor().set_element_type(Type.f32)\n",
    "\n",
    "# 5) Apply preprocessing modifying the original 'model'\n",
    "processed_model = ppp.build()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model to the MYRIAD device\n",
      "Total time: 6.596s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Load the model into the device\n",
    "print(f'Loading the model to the {device_name} device')\n",
    "start = time.time()\n",
    "compiled_model = core.compile_model(processed_model, device_name)\n",
    "end = time.time()\n",
    "print(f\"Total time: {end - start:.3f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference in synchronous mode\n",
      "305 / 3055\n",
      "Total time: 28.840s\n",
      "Average time: 0.095s\n"
     ]
    }
   ],
   "source": [
    "# Create infer requests\n",
    "print('Starting inference')\n",
    "start = time.time()\n",
    "results = []\n",
    "for i, x in enumerate(complete_tensor):\n",
    "    y = compiled_model.infer_new_request({0: np.expand_dims(x, 0)})\n",
    "    predictions = next(iter(y.values()))\n",
    "    probs = predictions.reshape(-1)\n",
    "    results.append(probs)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"\\r {i} / {len(complete_tensor)}\", end=\"\")\n",
    "end = time.time()\n",
    "print(f\"\\r{len(complete_tensor)} / {len(complete_tensor)}\")\n",
    "total = end - start\n",
    "average = total / len(complete_tensor)\n",
    "print(f\"Total time: {total:.3f}s\")\n",
    "print(f\"Average time: {average:.3f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.843\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy\n",
    "results = np.array(results)\n",
    "actual = np.array([0] * len(paths[0]) + [1] * len(paths[1]) + [2] * len(paths[2]))\n",
    "accuracy = np.mean(np.argmax(results, axis=1) == actual)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Comparison to torch model\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = 'model_mobilenet_v2.pth'\n",
    "model = models.mobilenet_v2()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "def test(model, test_loader, loss_fn, num_runs=5, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        count = 0\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "            count += 1\n",
    "            if count % 10 == 0:\n",
    "                print(f\"\\r{count} / {len(test_loader)}\", end=\"\")\n",
    "        print(f\"\\r{len(test_loader)} / {len(test_loader)}\")\n",
    "        accuracy = num_correct / num_examples\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    average_loss = total_loss / (num_runs * len(test_loader.dataset))\n",
    "    average_accuracy = total_accuracy / num_runs\n",
    "\n",
    "    print('Average Test Loss: {:.2f}, Average Test Accuracy: {:.2f}'.format(average_loss, average_accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 / 77: tensor([1, 2, 2, 1]) tensor([1, 2, 2, 1]) tensor([True, True, True, True])ue])\n",
      "Average Test Loss: 0.34, Average Test Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "path_data=os.path.join(\"..\", \"data\")\n",
    "dataset_mean = [0.2391, 0.4028, 0.4096]\n",
    "dataset_std = [0.2312, 0.3223, 0.3203]\n",
    "\n",
    "transform = transforms.Compose([v2.ToImage(),\n",
    "                                v2.Resize((int(256), int(256))),\n",
    "                                # v2.RandomHorizontalFlip(p=0.5),\n",
    "                                # v2.RandomVerticalFlip(p=0.5),\n",
    "                                v2.ToDtype(torch.float32, scale=True),\n",
    "                                v2.Grayscale(num_output_channels=3),\n",
    "                                v2.Normalize(dataset_mean,dataset_std)\n",
    "                                ])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_data,\n",
    "                                 transform=transform)\n",
    "test_loader = DataLoader(dataset, batch_size=4, pin_memory=False, shuffle=True)\n",
    "test(model, test_loader, torch.nn.CrossEntropyLoss(), num_runs=1, device=\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
