{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beefc598-b578-4420-ae2a-14ba2ea15a9e",
   "metadata": {},
   "source": [
    "# Train example notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe940bf-d307-4329-a62d-5b3810a293b9",
   "metadata": {},
   "source": [
    "This notebook is used to implement the training of a neural network for classification of `Cloud`, `Edge`, `Good` images. <br> It is advisable to use this notebook to get practice and debug your code. To speed up the execution, once you are ready, you should move to a scripted version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79b286-de2e-4f79-b04f-f5dc77e50c59",
   "metadata": {},
   "source": [
    "## 1. - Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a0112-75c6-4fd4-887d-0c1fe660c9ac",
   "metadata": {},
   "source": [
    "Select `CUDA_VISIBLE_DEVICES` to the `Graphics Proceesing Unit (GPU)` index that you want to use to enable the use of GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7db3603-a5ec-4fd2-ae28-4571762fc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62227b7f-8c1a-479f-ae34-84611d656702",
   "metadata": {},
   "source": [
    "Enabling autoreload of different packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09a54f6-3fc4-463a-a93f-72cdd4ea75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26166ece-1cb3-4231-b2c6-3df9b39488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(\"..\", \"data\"))\n",
    "sys.path.insert(1, os.path.join(\"..\", \"utils\"))\n",
    "from torchvision import datasets, transforms\n",
    "from plot_utils import plot_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e285782-59e0-4816-bcf8-bf66981200a2",
   "metadata": {},
   "source": [
    "## 2. - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7a7a3-d603-4050-9fb4-f1a20c09a072",
   "metadata": {},
   "source": [
    "### 2.1 - Creating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d110f-1b25-4445-bd84-1a29f9261e7e",
   "metadata": {},
   "source": [
    "Now we read the images from the target directory `path_data`. Set `path_data` to the directory containing the `Cloud`, `Edge`, `Good` subfolders.  Moreover, it will automatically split the total dataset into the train, cross validation and test splits by using a pseudo-random splitting algorithm. You can reproduce the split by specifying the variable `seed`. **NB**:\n",
    "- The train split contains 70% of the whole images.\n",
    "- The valid splits contains 15% of the whole images.\n",
    "- The test splits contains 15% of the whole images.<br>**YOU MUST NOT CHANGE THE TEST SPLIT SIZE!!!**\n",
    "\n",
    "The datase loader defines the transforms to be applied to each batch of imageis being loaded. These can be used to augment the dataset and limited teh amount of input paramters to the network by for exampling resizing the image or converting it to greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b8b832-ce8e-4512-9bdb-6c73d715feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder (update the variable to your path).\n",
    "path_data=os.path.join(\"..\", \"data\")\n",
    "# Seed value\n",
    "seed=22\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image_width = 1024\n",
    "image_height = 1942\n",
    "scale_factor = 0.1\n",
    "\n",
    "valid_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "dataset_mean = [0.2391, 0.4028, 0.4096]\n",
    "dataset_std = [0.2312, 0.3223, 0.3203]\n",
    "\n",
    "transform = transforms.Compose([v2.ToImage(),\n",
    "                                v2.Resize((int(256), int(256))),\n",
    "                                v2.RandomHorizontalFlip(p=0.5),\n",
    "                                v2.RandomVerticalFlip(p=0.5),\n",
    "                                v2.ToDtype(torch.float32, scale=True),\n",
    "                                v2.Grayscale(num_output_channels=1),\n",
    "                                v2.Normalize((dataset_mean),(dataset_std))\n",
    "                                ])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_data, \n",
    "                                 transform=transform)\n",
    "\n",
    "n_val = int(np.floor(valid_size * len(dataset)))\n",
    "n_test = int(np.floor(test_size * len(dataset)))\n",
    "n_train = len(dataset) - n_val - n_test\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c1e33-6c9d-4020-bb4b-9a95cd7e77fa",
   "metadata": {},
   "source": [
    "### 2.2. - Create data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5c989-13e1-48b6-bb99-b09027a94675",
   "metadata": {},
   "source": [
    "The next lines will create a dataloader. A data loader is used to break the dataset into batches of a size `batch_size`. <br> This is useful to ensure that your dataset will fit into your memory and to create a \"stochastic\" implementation of gradient descent. <br> For more information, please, check: [data loader](https://www.educative.io/answers/what-is-pytorch-dataloader).<br>\n",
    "Specify `batch_size` (**Hint**: use powers of 2. Typical values are between 8 and 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0f8a6d-d620-424d-abae-48789e9c64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split:  {0: 61, 1: 73, 2: 80}\n",
      "Test split:  {0: 13, 1: 12, 2: 20}\n",
      "Validation split:  {0: 16, 1: 12, 2: 17}\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "# Train loader\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "# Cross validation data loader\n",
    "valid_loader = DataLoader(val_ds, batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "# Test data loader\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, pin_memory=False, shuffle=True)\n",
    "\n",
    "#0 - cloud\n",
    "#1 - edge\n",
    "#2 - good\n",
    "\n",
    "unique, counts = np.unique(torch.tensor([train_ds.dataset.targets[i] for i in train_ds.indices]), return_counts=True)\n",
    "print(\"Train split: \", dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(torch.tensor([test_ds.dataset.targets[i] for i in test_ds.indices]), return_counts=True)\n",
    "print(\"Test split: \", dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(torch.tensor([val_ds.dataset.targets[i] for i in val_ds.indices]), return_counts=True)\n",
    "print(\"Validation split: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772b7c14-2bf3-47c7-a2ff-ab80c5aa2c0a",
   "metadata": {},
   "source": [
    "Now, it is your turn! Add your code below to load a Neural Network model, select optimizers, learning rate and perform training. <br>\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec454c-0b6d-411c-bc63-7223de91dabd",
   "metadata": {},
   "source": [
    "## 3 - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac823d7b-1979-441d-91a8-d81a162f6012",
   "metadata": {},
   "source": [
    "### 3.1 - Defining the model and optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bdd6be-9ce4-4798-a3f9-06844e354618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20181212\\AppData\\Local\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\20181212\\AppData\\Local\\anaconda3\\envs\\OMICRON\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "\n",
    "    \n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "    \n",
    "import torch.optim as optim\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Initialize or load history\n",
    "training_history = {\"train_loss\": [], \"val_loss\": [], \"accuracy\": []}\n",
    "\n",
    "# Assuming model, optimizer, train_loader, val_loader are defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03b21b-6c93-4bca-9de9-06df35946714",
   "metadata": {},
   "source": [
    "### 3.1 - The training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f968f7-1932-4bf5-8c84-b21773d38d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "\n",
    "    \n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "    \n",
    "import torch.optim as optim\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Initialize or load history\n",
    "training_history = {\"train_loss\": [], \"val_loss\": [], \"accuracy\": []}\n",
    "\n",
    "# Assuming model, optimizer, train_loader, val_loader are defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs, device, history):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output, targets)\n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        history[\"train_loss\"].append(training_loss)\n",
    "        history[\"val_loss\"].append(valid_loss)\n",
    "        history[\"accuracy\"].append(num_correct / num_examples)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Training Loss: {training_loss:.2f}, Validation Loss: {valid_loss:.2f}, Accuracy: {num_correct / num_examples:.2f}')\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(history[\"train_loss\"], 'r-', label='Training Loss')\n",
    "    plt.plot(history[\"val_loss\"], 'g-', label='Validation Loss')\n",
    "    plt.plot(history[\"accuracy\"], 'b-', label='Accuracy')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def test(model, test_loader, loss_fn, num_runs=5, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total_accuracy = 0.0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "\n",
    "        accuracy = num_correct / num_examples\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    average_loss = total_loss / (num_runs * len(test_loader.dataset))\n",
    "    average_accuracy = total_accuracy / num_runs\n",
    "\n",
    "    print('Average Test Loss: {:.2f}, Average Test Accuracy: {:.2f}'.format(average_loss, average_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b60d0e-bf3e-461e-8017-f5b124dc08c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb246dda6454663baadba54378a38ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Select Model:', index=45, options=('_api', '_meta', '_utilâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, HBox, VBox, FloatText, Layout, Checkbox\n",
    "from IPython.display import display, clear_output\n",
    "from torchvision import models\n",
    "\n",
    "# Global variables\n",
    "global model\n",
    "model = None  # Initialize model as None\n",
    "global saved_models\n",
    "saved_models = []  # List to store names of saved models\n",
    "\n",
    "# Functions\n",
    "def get_available_models():\n",
    "    \"\"\"Return a list of available models from torchvision.\"\"\"\n",
    "    return [name for name in dir(models) if name.islower() and not name.startswith(\"__\")]\n",
    "\n",
    "def get_saved_models():\n",
    "    \"\"\"Return a sorted list of saved models.\"\"\"\n",
    "    saved_models = [filename[:-4] for filename in os.listdir('.') if filename.endswith(('.pth', '.png'))]\n",
    "    return sorted(set(saved_models))  # Sort and remove duplicates\n",
    "\n",
    "def load_new_model(change):\n",
    "    \"\"\"Load a new model based on the selection and pretrained status.\"\"\"\n",
    "    global model\n",
    "    model_name = model_selector.value\n",
    "    pretrained = pretrained_checkbox.value\n",
    "    \n",
    "    if model_name in get_available_models():\n",
    "        model = getattr(models, model_name)(pretrained=pretrained)\n",
    "        model.to(device)\n",
    "        clear_output(wait=True)\n",
    "        with output_area:\n",
    "            print(f\"Loaded model: {model_name} (Pretrained: {pretrained})\")\n",
    "        update_saved_models_list()\n",
    "    else:\n",
    "        with output_area:\n",
    "            print(f\"Error: {model_name} not found in available models\")\n",
    "\n",
    "def train_model(b):\n",
    "    \"\"\"Train the model and update the plot.\"\"\"\n",
    "    global training_history\n",
    "    epochs = epoch_slider.value\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        training_history = train(model, optimizer, torch.nn.CrossEntropyLoss(), train_loader, valid_loader, epochs, device, training_history)\n",
    "        update_plot()\n",
    "\n",
    "def plot_history_button_clicked(b):\n",
    "    \"\"\"Update the plot.\"\"\"\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        update_plot()\n",
    "\n",
    "def test_model(b):\n",
    "    \"\"\"Test the model.\"\"\"\n",
    "    num_runs = runs_slider.value\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        test(model, test_loader, torch.nn.CrossEntropyLoss(), num_runs=num_runs, device=device)\n",
    "\n",
    "def load_model(change):\n",
    "    model_name = model_dropdown.value\n",
    "    model_path = os.path.join('models', f'{model_name}.pth')\n",
    "    \n",
    "    # Load the model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    with output_area:\n",
    "        print(f\"Model '{model_name}' loaded.\")\n",
    "\n",
    "def save_model(b):\n",
    "    model_name = model_name_text.value\n",
    "    model_dir = 'models'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, f'{model_name}.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Update the list of available models\n",
    "    update_model_dropdown()\n",
    "    \n",
    "    with output_area:\n",
    "        print(f\"Model saved as {model_path}\")\n",
    "\n",
    "def load_saved_model(change):\n",
    "    global model\n",
    "    selected_model_name = saved_model_selector.value\n",
    "    \n",
    "    try:\n",
    "        # Check if the selected model name is a valid saved model\n",
    "        if selected_model_name not in get_saved_models():\n",
    "            raise ValueError(f\"Invalid model name: {selected_model_name}\")\n",
    "        \n",
    "        model_dir = 'models'\n",
    "        model_path = os.path.join(model_dir, f'{selected_model_name}.pth')\n",
    "        \n",
    "        # Load the model from the specified directory\n",
    "        loaded_model = torch.load(model_path)\n",
    "        loaded_model.to(device)\n",
    "        \n",
    "        # Check if the loaded model is not None\n",
    "        if loaded_model is not None:\n",
    "            model = loaded_model\n",
    "            clear_output(wait=True)\n",
    "            with output_area:\n",
    "                print(f\"Loaded saved model: {selected_model_name} from {model_path}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Error loading saved model: {selected_model_name}. Loaded model is None.\")\n",
    "    except Exception as e:\n",
    "        with output_area:\n",
    "            print(f\"Error loading saved model: {selected_model_name}. {str(e)}\")\n",
    "\n",
    "\n",
    "def update_saved_models_list():\n",
    "    \"\"\"Update the list of saved models.\"\"\"\n",
    "    global saved_models\n",
    "    saved_models = get_saved_models()\n",
    "    saved_model_selector.options = saved_models\n",
    "\n",
    "def update_plot(ax=None, y_limit=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(training_history[\"train_loss\"], 'r-', label='Training Loss')\n",
    "    ax.plot(training_history[\"val_loss\"], 'g-', label='Validation Loss')\n",
    "    ax.plot(training_history[\"accuracy\"], 'b-', label='Accuracy')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Metrics')\n",
    "    ax.set_title('Training Progress')\n",
    "    ax.legend()\n",
    "    if y_limit is not None:\n",
    "        ax.set_ylim(bottom=0, top=y_limit)\n",
    "    \n",
    "    # If ax is provided, show the existing figure\n",
    "    if ax is not None:\n",
    "        plt.show()\n",
    "\n",
    "# Widgets\n",
    "model_selector = widgets.Dropdown(options=get_available_models(), value='mobilenet_v3_small', description='Select Model:')\n",
    "pretrained_checkbox = widgets.Checkbox(value=True, description='Pretrained')\n",
    "load_model_button = widgets.Button(description='Load New Model')\n",
    "load_model_button.on_click(load_new_model)\n",
    "\n",
    "saved_model_selector = widgets.Dropdown(options=get_saved_models(), value=None, description='Select Saved Model:')\n",
    "load_saved_model_button = widgets.Button(description='Load Saved Model')\n",
    "load_saved_model_button.on_click(load_saved_model)\n",
    "\n",
    "model_name_text = widgets.Text(value='model', description='Model Name:')\n",
    "save_model_button = widgets.Button(description='Save Model')\n",
    "save_model_button.on_click(save_model)\n",
    "\n",
    "epoch_slider = widgets.IntSlider(value=1, min=5, max=100, step=1, description='Epochs:')\n",
    "train_button = widgets.Button(description='Train Model')\n",
    "train_button.on_click(train_model)\n",
    "\n",
    "y_limit_text = FloatText(value=1.0, description='Y Limit:', layout=Layout(width='80px'))\n",
    "plot_button = widgets.Button(description='Plot History')\n",
    "plot_button.on_click(plot_history_button_clicked)\n",
    "\n",
    "plot_name_text = widgets.Text(value='plot', description='Plot Name:')\n",
    "save_plot_button = widgets.Button(description='Save Plot')\n",
    "save_plot_button.on_click(save_plot)  # Implement save_plot function if needed\n",
    "\n",
    "test_button = widgets.Button(description='Test Model')\n",
    "test_button.on_click(test_model)\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# UI Layout\n",
    "ui = VBox([\n",
    "    HBox([model_selector, pretrained_checkbox, load_model_button]),\n",
    "    widgets.HTML(value='<hr>'),\n",
    "    HBox([saved_model_selector, load_saved_model_button]),\n",
    "    HBox([model_name_text, save_model_button]),\n",
    "    widgets.HTML(value='<hr>'),\n",
    "    HBox([epoch_slider, train_button]),\n",
    "    HBox([y_limit_text, plot_button]),\n",
    "    HBox([plot_name_text, save_plot_button]),\n",
    "    output_area\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae674b-621b-41c4-82f2-a333e516b015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
